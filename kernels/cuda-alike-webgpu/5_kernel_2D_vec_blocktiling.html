
<!DOCTYPE html>
<html>
<head>
    <title>WebGPU Matrix Multiplication - Vectorized CUDA-like Block Tiling</title>
    <style>
        #output { 
            font-family: monospace; 
            white-space: pre; 
            margin: 20px; 
            font-size: 14px;
        }
        .correct { color: green; }
        .incorrect { color: red; }
        .performance { 
            margin-top: 20px;
            font-weight: bold;
            color: #0066cc;
        }
        .stats {
            margin-top: 10px;
            color: #666;
            padding: 10px;
            background-color: #f8f9fa;
            border-radius: 4px;
        }
        .gflops {
            color: #0066cc;
            font-weight: bold;
        }
        .timing {
            color: #666;
            font-style: italic;
        }
        .test-case {
            margin: 20px;
            padding: 15px;
            border: 1px solid #ddd;
            border-radius: 5px;
            background-color: #f5f5f5;
        }
    </style>
</head>
<body>
    <h1>WebGPU Matrix Multiplication with Vectorized 2D Block Tiling</h1>
    <div id="output"></div>
    <script type="text/javascript">
        // Constants matching CUDA implementation
        const LARGE_MATRIX_SIZE = 4096;
        const TEST_MATRIX_SIZE = 4;
        const BK = 8;    // Block size K dimension (fixed)
        const TM = 8;    // Thread tile M dimension (fixed)
        const TN = 8;    // Thread tile N dimension (fixed)
        const NUM_ITERATIONS = 16;  // Number of benchmark iterations
        const WARMUP_ITERATIONS = 5; // Number of warmup iterations

        // Test matrices (4x4)
        const testMatrixA = new Float32Array([
            1, 2, 3, 4,
            5, 6, 7, 8,
            9, 10, 11, 12,
            13, 14, 15, 16
        ]);

        const testMatrixB = new Float32Array([
            1, 2, 3, 4,
            5, 6, 7, 8,
            9, 10, 11, 12,
            13, 14, 15, 16
        ]);

        function getBlockSize(size) {
            return size >= 128 ? 128 : 64;
        }

        function getThreadsPerBlock(bm, bn) {
            return (bm * bn) / (TM * TN);
        }

        function calculateGFLOPs(M, N, K, timeInMs) {
            const operations = 2n * BigInt(M) * BigInt(N) * BigInt(K);
            const timeInSeconds = timeInMs / 1000;
            const gflops = Number(operations) / (timeInSeconds * 1e9);
            return gflops;
        }

        function generateRandomMatrix(size) {
            const matrix = new Float32Array(size * size);
            for (let i = 0; i < matrix.length; i++) {
                matrix[i] = Math.random() * 2 - 1;
            }
            return matrix;
        }

        function getCPUResult(firstMatrix, secondMatrix, M, N, K, row, col) {
            let sum = 0;
            for (let k = 0; k < K; k++) {
                sum += firstMatrix[row * K + k] * secondMatrix[k * N + col];
            }
            return sum;
        }

        function verifyResults(firstMatrix, secondMatrix, gpuResult, M, N, K, checkAll = false) {
            const results = [];
            const positions = new Set();
            
            if (checkAll && M <= 4) {
                // Check all positions for small matrices
                for (let i = 0; i < M; i++) {
                    for (let j = 0; j < N; j++) {
                        positions.add(`${i},${j}`);
                    }
                }
            } else {
                // Random sampling for larger matrices
                const numChecks = 50;
                while(positions.size < numChecks) {
                    const row = Math.floor(Math.random() * M);
                    const col = Math.floor(Math.random() * N);
                    positions.add(`${row},${col}`);
                }
            }
            
            for(const pos of positions) {
                const [row, col] = pos.split(',').map(Number);
                const cpuResult = getCPUResult(firstMatrix, secondMatrix, M, N, K, row, col);
                const gpuResultVal = gpuResult[row * N + col];
                const diff = Math.abs(cpuResult - gpuResultVal);
                const isCorrect = diff < 0.01;
                
                results.push({
                    row,
                    col,
                    cpuResult,
                    gpuResult: gpuResultVal,
                    isCorrect,
                    diff
                });
            }

            return results;
        }

        async function runKernel(device, computePipeline, bindGroup, gridDimX, gridDimY) {
            const commandEncoder = device.createCommandEncoder();
            const passEncoder = commandEncoder.beginComputePass();
            passEncoder.setPipeline(computePipeline);
            passEncoder.setBindGroup(0, bindGroup);
            passEncoder.dispatchWorkgroups(gridDimX, gridDimY);
            passEncoder.end();
            device.queue.submit([commandEncoder.finish()]);
            await device.queue.onSubmittedWorkDone();
        }

        async function runMatrixMultiplication(device, firstMatrix, secondMatrix, matrixSize, isTestCase = false) {
            const BM = getBlockSize(matrixSize);
            const BN = getBlockSize(matrixSize);
            const THREADS_PER_BLOCK = getThreadsPerBlock(BM, BN);

            const shaderModule = device.createShaderModule({
                code: `
                    struct Matrix {
                        size : vec2f,
                        numbers: array<f32>,
                    }

                    @group(0) @binding(0) var<storage, read> firstMatrix : Matrix;
                    @group(0) @binding(1) var<storage, read> secondMatrix : Matrix;
                    @group(0) @binding(2) var<storage, read_write> resultMatrix : Matrix;

                    var<workgroup> tileA: array<array<f32, ${BK}>, ${BM}>;
                    var<workgroup> tileB: array<array<f32, ${BN}>, ${BK}>;

                    const BM: u32 = ${BM}u;
                    const BN: u32 = ${BN}u;
                    const BK: u32 = ${BK}u;
                    const TM: u32 = ${TM}u;
                    const TN: u32 = ${TN}u;
                    const THREADS_PER_BLOCK: u32 = ${THREADS_PER_BLOCK}u;

                    fn vec4_dot(a: vec4f, b: vec4f) -> f32 {
                        return dot(a, b);
                    }

                    @compute @workgroup_size(${THREADS_PER_BLOCK})
                    fn main(
                        @builtin(global_invocation_id) global_id : vec3<u32>,
                        @builtin(local_invocation_id) local_id : vec3<u32>,
                        @builtin(workgroup_id) workgroup_id : vec3<u32>
                    ) {
                        let threadCol = local_id.x % (BN / TN);
                        let threadRow = local_id.x / (BN / TN);

                        let innerRowA = local_id.x / BK;
                        let innerColA = local_id.x % BK;
                        let strideA = THREADS_PER_BLOCK / BK;
                        
                        let innerRowB = local_id.x / BN;
                        let innerColB = local_id.x % BN;
                        let strideB = THREADS_PER_BLOCK / BN;

                        var threadResults: array<f32, ${TM * TN}>;
                        for(var i = 0u; i < ${TM * TN}; i = i + 1u) {
                            threadResults[i] = 0.0;
                        }

                        let blockRowA = workgroup_id.y * BM;
                        let blockColB = workgroup_id.x * BN;

                        let K = u32(firstMatrix.size.x);
                        
                        for(var bkIdx = 0u; bkIdx < K; bkIdx = bkIdx + BK) {
                            // Load matrix A into shared memory
                            for(var i = 0u; i < BM; i = i + strideA) {
                                let gmemIdx = (blockRowA + innerRowA + i) * K + bkIdx + innerColA;
                                if((blockRowA + innerRowA + i) < u32(firstMatrix.size.y) && 
                                   (bkIdx + innerColA) < K) {
                                    tileA[innerRowA + i][innerColA] = firstMatrix.numbers[gmemIdx];
                                } else {
                                    tileA[innerRowA + i][innerColA] = 0.0;
                                }
                            }

                            // Load matrix B into shared memory
                            for(var i = 0u; i < BK; i = i + strideB) {
                                let gmemIdx = (bkIdx + innerRowB + i) * u32(secondMatrix.size.x) + 
                                            blockColB + innerColB;
                                if((bkIdx + innerRowB + i) < K && 
                                   (blockColB + innerColB) < u32(secondMatrix.size.x)) {
                                    tileB[innerRowB + i][innerColB] = secondMatrix.numbers[gmemIdx];
                                } else {
                                    tileB[innerRowB + i][innerColB] = 0.0;
                                }
                            }

                            workgroupBarrier();

                            // Compute using vectorized operations where possible
                            for(var dotIdx = 0u; dotIdx < BK; dotIdx = dotIdx + 4u) {
                                // Process 4 elements at a time using vec4f
                                for(var m = 0u; m < TM; m = m + 1u) {
                                    let rowA = threadRow * TM + m;
                                    let vecA = vec4f(
                                        tileA[rowA][dotIdx],
                                        tileA[rowA][dotIdx + 1u],
                                        tileA[rowA][dotIdx + 2u],
                                        tileA[rowA][dotIdx + 3u]
                                    );

                                    for(var n = 0u; n < TN; n = n + 1u) {
                                        let colB = threadCol * TN + n;
                                        let vecB = vec4f(
                                            tileB[dotIdx][colB],
                                            tileB[dotIdx + 1u][colB],
                                            tileB[dotIdx + 2u][colB],
                                            tileB[dotIdx + 3u][colB]
                                        );

                                        threadResults[m * TN + n] += vec4_dot(vecA, vecB);
                                    }
                                }
                            }

                            workgroupBarrier();
                        }

                        for(var m = 0u; m < TM; m = m + 1u) {
                            for(var n = 0u; n < TN; n = n + 1u) {
                                let globalRow = blockRowA + threadRow * TM + m;
                                let globalCol = blockColB + threadCol * TN + n;
                                
                                if(globalRow < u32(resultMatrix.size.y) && 
                                   globalCol < u32(resultMatrix.size.x)) {
                                    let gmemIdx = globalRow * u32(resultMatrix.size.x) + globalCol;
                                    resultMatrix.numbers[gmemIdx] = threadResults[m * TN + n];
                                }
                            }
                        }
                    }
                `
            });

            const resultMatrixBuffer = new Float32Array(matrixSize * matrixSize);

            const gpuBufferFirstMatrix = device.createBuffer({
                mappedAtCreation: true,
                size: firstMatrix.byteLength + 8,
                usage: GPUBufferUsage.STORAGE
            });
            new Float32Array(gpuBufferFirstMatrix.getMappedRange()).set([matrixSize, matrixSize, ...firstMatrix]);
            gpuBufferFirstMatrix.unmap();

            const gpuBufferSecondMatrix = device.createBuffer({
                mappedAtCreation: true,
                size: secondMatrix.byteLength + 8,
                usage: GPUBufferUsage.STORAGE
            });
            new Float32Array(gpuBufferSecondMatrix.getMappedRange()).set([matrixSize, matrixSize, ...secondMatrix]);
            gpuBufferSecondMatrix.unmap();

            const gpuBufferResultMatrix = device.createBuffer({
                mappedAtCreation: true,
                size: resultMatrixBuffer.byteLength + 8,
                usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC
            });
            new Float32Array(gpuBufferResultMatrix.getMappedRange()).set([matrixSize, matrixSize]);
            gpuBufferResultMatrix.unmap();

            const bindGroupLayout = device.createBindGroupLayout({
                entries: [
                    { binding: 0, visibility: GPUShaderStage.COMPUTE, buffer: { type: "read-only-storage" }},
                    { binding: 1, visibility: GPUShaderStage.COMPUTE, buffer: { type: "read-only-storage" }},
                    { binding: 2, visibility: GPUShaderStage.COMPUTE, buffer: { type: "storage" }}
                ]
            });

            const bindGroup = device.createBindGroup({
                layout: bindGroupLayout,
                entries: [
                    { binding: 0, resource: { buffer: gpuBufferFirstMatrix }},
                    { binding: 1, resource: { buffer: gpuBufferSecondMatrix }},
                    { binding: 2, resource: { buffer: gpuBufferResultMatrix }}
                ]
            });

            const pipelineLayout = device.createPipelineLayout({
                bindGroupLayouts: [bindGroupLayout]
            });

            const computePipeline = device.createComputePipeline({
                layout: pipelineLayout,
                compute: {
                    module: shaderModule,
	            entryPoint: "main"
                }
            });

            const gridDimX = Math.ceil(matrixSize / BN);
            const gridDimY = Math.ceil(matrixSize / BM);

            let kernelTimes = [];

            if (!isTestCase) {
                // Run warmup iterations
                for (let i = 0; i < WARMUP_ITERATIONS; i++) {
                    await runKernel(device, computePipeline, bindGroup, gridDimX, gridDimY);
                }

                // Run benchmark iterations
                for (let i = 0; i < NUM_ITERATIONS; i++) {
                    const startTime = performance.now();
                    await runKernel(device, computePipeline, bindGroup, gridDimX, gridDimY);
                    const endTime = performance.now();
                    kernelTimes.push(endTime - startTime);
                }
            } else {
                // For test case, just run once
                const startTime = performance.now();
                await runKernel(device, computePipeline, bindGroup, gridDimX, gridDimY);
                const endTime = performance.now();
                kernelTimes.push(endTime - startTime);
            }

            // Read back results
            const gpuReadBuffer = device.createBuffer({
                size: resultMatrixBuffer.byteLength + 8,
                usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ
            });

            const readCommandEncoder = device.createCommandEncoder();
            readCommandEncoder.copyBufferToBuffer(
                gpuBufferResultMatrix, 0,
                gpuReadBuffer, 0,
                resultMatrixBuffer.byteLength + 8
            );

            device.queue.submit([readCommandEncoder.finish()]);

            await gpuReadBuffer.mapAsync(GPUMapMode.READ);
            const result = new Float32Array(gpuReadBuffer.getMappedRange().slice(8));
            gpuReadBuffer.unmap();

            return {
                result,
                kernelTimes,
                matrixSize
            };
        }

        async function init() {
            const output = document.getElementById('output');
            
            if (!navigator.gpu) {
                output.textContent = 'WebGPU not supported! Please use a WebGPU-enabled browser.';
                return;
            }

            const adapter = await navigator.gpu.requestAdapter();
            if (!adapter) {
                output.textContent = 'Failed to get GPU adapter.';
                return;
            }
            const device = await adapter.requestDevice();

            // First run the 4x4 test case
            output.textContent = '=== Running 4x4 Test Case ===\n\n';
            const testCase = await runMatrixMultiplication(device, testMatrixA, testMatrixB, TEST_MATRIX_SIZE, true);
            
            const testStatsDiv = document.createElement('div');
            testStatsDiv.className = 'test-case';
            testStatsDiv.innerHTML = `
4x4 Test Case Configuration:
• Matrix Size: ${TEST_MATRIX_SIZE}x${TEST_MATRIX_SIZE}
• Block dimensions (BM×BN): ${getBlockSize(TEST_MATRIX_SIZE)}×${getBlockSize(TEST_MATRIX_SIZE)}
• Kernel execution time: ${testCase.kernelTimes[0].toFixed(2)}ms

Test Matrix A:
${Array.from({ length: TEST_MATRIX_SIZE }, (_, i) => 
    Array.from(testMatrixA.slice(i * TEST_MATRIX_SIZE, (i + 1) * TEST_MATRIX_SIZE))
        .join('\t')
).join('\n')}

Test Matrix B:
${Array.from({ length: TEST_MATRIX_SIZE }, (_, i) => 
    Array.from(testMatrixB.slice(i * TEST_MATRIX_SIZE, (i + 1) * TEST_MATRIX_SIZE))
        .join('\t')
).join('\n')}

Result Matrix:
${Array.from({ length: TEST_MATRIX_SIZE }, (_, i) => 
    Array.from(testCase.result.slice(i * TEST_MATRIX_SIZE, (i + 1) * TEST_MATRIX_SIZE))
        .map(n => n.toFixed(2))
        .join('\t')
).join('\n')}
`;
            output.appendChild(testStatsDiv);

            // Now run the large matrix multiplication with iterations
            output.textContent += '\n\n=== Running Large Matrix Multiplication ===\n\n';
            
            const genStartTime = performance.now();
            const firstMatrix = generateRandomMatrix(LARGE_MATRIX_SIZE);
            const secondMatrix = generateRandomMatrix(LARGE_MATRIX_SIZE);
            const genEndTime = performance.now();

            output.textContent += `Matrix generation time: ${(genEndTime - genStartTime).toFixed(2)}ms\n`;
            
            // Run warmup iterations
            output.textContent += `Running ${WARMUP_ITERATIONS} warmup iterations...\n\n`;
            const warmupDiv = document.createElement('div');
            warmupDiv.style.fontFamily = 'monospace';
            warmupDiv.style.color = '#666666';
            output.appendChild(warmupDiv);

            // Run benchmark iterations
            output.textContent += `\nRunning ${NUM_ITERATIONS} benchmark iterations...\n\n`;
            const iterationsDiv = document.createElement('div');
            iterationsDiv.style.fontFamily = 'monospace';
            output.appendChild(iterationsDiv);

            const largeCase = await runMatrixMultiplication(device, firstMatrix, secondMatrix, LARGE_MATRIX_SIZE, false);
            
            // Display iteration results
            largeCase.kernelTimes.forEach((time, index) => {
                const gflops = calculateGFLOPs(LARGE_MATRIX_SIZE, LARGE_MATRIX_SIZE, LARGE_MATRIX_SIZE, time);
                const iterSpan = document.createElement('div');
                iterSpan.textContent = `Iteration ${index + 1}: ${time.toFixed(2)}ms (${gflops.toFixed(2)} GFLOP/s)\n`;
                iterationsDiv.appendChild(iterSpan);
            });

            // Calculate statistics
            const avgKernelTime = largeCase.kernelTimes.reduce((a, b) => a + b, 0) / NUM_ITERATIONS;
            const minKernelTime = Math.min(...largeCase.kernelTimes);
            const maxKernelTime = Math.max(...largeCase.kernelTimes);
            
            const avgGflops = calculateGFLOPs(LARGE_MATRIX_SIZE, LARGE_MATRIX_SIZE, LARGE_MATRIX_SIZE, avgKernelTime);
            const maxGflops = calculateGFLOPs(LARGE_MATRIX_SIZE, LARGE_MATRIX_SIZE, LARGE_MATRIX_SIZE, minKernelTime);
            
            const statsDiv = document.createElement('div');
            statsDiv.className = 'stats';
            statsDiv.innerHTML = `
CUDA-like Configuration:
• Matrix Size: ${LARGE_MATRIX_SIZE}x${LARGE_MATRIX_SIZE}
• Block dimensions (BM×BN): ${getBlockSize(LARGE_MATRIX_SIZE)}×${getBlockSize(LARGE_MATRIX_SIZE)}
• Block size K: ${BK}
• Thread tile dimensions (TM×TN): ${TM}×${TN}
• Threads per block: ${getThreadsPerBlock(getBlockSize(LARGE_MATRIX_SIZE), getBlockSize(LARGE_MATRIX_SIZE))}
• Grid dimensions: ${Math.ceil(LARGE_MATRIX_SIZE/getBlockSize(LARGE_MATRIX_SIZE))}×${Math.ceil(LARGE_MATRIX_SIZE/getBlockSize(LARGE_MATRIX_SIZE))}

Timing Statistics:
• Matrix generation: ${(genEndTime - genStartTime).toFixed(2)}ms
• Average kernel execution: ${avgKernelTime.toFixed(2)}ms
• Min kernel execution: ${minKernelTime.toFixed(2)}ms
• Max kernel execution: ${maxKernelTime.toFixed(2)}ms

Performance:
• Average performance: ${avgGflops.toFixed(2)} GFLOP/s
• Peak performance: ${maxGflops.toFixed(2)} GFLOP/s
• Memory per matrix: ${(LARGE_MATRIX_SIZE * LARGE_MATRIX_SIZE * 4 / (1024 * 1024)).toFixed(2)} MB
`;
            output.appendChild(statsDiv);

            // Verify results
            output.textContent += '\nVerifying 50 random positions for large matrix...\n\n';

            const verificationResults = verifyResults(
                firstMatrix,
                secondMatrix,
                largeCase.result,
                LARGE_MATRIX_SIZE,
                LARGE_MATRIX_SIZE,
                LARGE_MATRIX_SIZE
            );

            let allCorrect = true;
            let maxDiff = 0;
            let avgDiff = 0;

            for (const check of verificationResults) {
                maxDiff = Math.max(maxDiff, check.diff);
                avgDiff += check.diff;

                const message = `Position [${check.row},${check.col}]: ` +
                              `GPU = ${check.gpuResult.toFixed(6)}, ` +
                              `CPU = ${check.cpuResult.toFixed(6)} ` +
                              `Diff: ${check.diff.toFixed(6)} ` +
                              `${check.isCorrect ? '✓' : '✗'}\n`;
                
                const span = document.createElement('span');
                span.textContent = message;
                span.className = check.isCorrect ? 'correct' : 'incorrect';
                output.appendChild(span);

                if (!check.isCorrect) allCorrect = false;
            }

            avgDiff /= verificationResults.length;

            const verificationStatsDiv = document.createElement('div');
            verificationStatsDiv.className = 'stats';
            verificationStatsDiv.textContent = `
Verification Statistics:
• Positions checked: ${verificationResults.length}
• Maximum difference: ${maxDiff.toFixed(6)}
• Average difference: ${avgDiff.toFixed(6)}
`;
            output.appendChild(verificationStatsDiv);

            const summarySpan = document.createElement('span');
            summarySpan.textContent = `\nOverall Verification: ${allCorrect ? 'PASSED ✓' : 'FAILED ✗'}`;
            summarySpan.className = allCorrect ? 'correct' : 'incorrect';
            output.appendChild(summarySpan);

            const perfSpan = document.createElement('div');
            perfSpan.className = 'performance';
            perfSpan.textContent = `\nAverage kernel execution time: ${avgKernelTime.toFixed(2)}ms`;
            output.appendChild(perfSpan);
        }

        init();
    </script>
</body>
</html>

